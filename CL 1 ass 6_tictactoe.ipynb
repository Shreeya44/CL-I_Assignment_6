{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666bd41f",
   "metadata": {},
   "source": [
    "## Reinforcement Learning \n",
    "\n",
    "Build a Tic-Tac-Toe game using reinforcement learning in Python by using following \n",
    "tasks \n",
    "a. Setting up the environment \n",
    "b. Defining the Tic-Tac-Toe game \n",
    "c. Building the reinforcement learning model \n",
    "d. Training the model \n",
    "e. Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ba31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AI...\n",
      "Episode 0 completed\n",
      "Episode 1000 completed\n",
      "Episode 2000 completed\n",
      "Episode 3000 completed\n",
      "Episode 4000 completed\n",
      "Episode 5000 completed\n",
      "Episode 6000 completed\n",
      "Episode 7000 completed\n",
      "Episode 8000 completed\n",
      "Episode 9000 completed\n",
      "Training completed!\n",
      "Do you want to play first? (y/n): y\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter your move (0-8): 1\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "AI plays move: 5\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "|   |   | O |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter your move (0-8): 4\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "|   | X | O |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "AI plays move: 0\n",
      "-------------\n",
      "| O | X |   |\n",
      "-------------\n",
      "|   | X | O |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter your move (0-8): 7\n",
      "-------------\n",
      "| O | X |   |\n",
      "-------------\n",
      "|   | X | O |\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "You won!\n",
      "Play again? (y/n): n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class TicTacToeEnv:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1  # 1 for X, -1 for O\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        return str(self.board.flatten().tolist())\n",
    "    \n",
    "    def is_valid_move(self, action):\n",
    "        row, col = action // 3, action % 3\n",
    "        return self.board[row][col] == 0\n",
    "    \n",
    "    def get_valid_moves(self):\n",
    "        return [i for i in range(9) if self.is_valid_move(i)]\n",
    "    \n",
    "    def check_winner(self):\n",
    "        # Check rows, columns and diagonals\n",
    "        for i in range(3):\n",
    "            if abs(sum(self.board[i, :])) == 3:\n",
    "                return self.board[i, 0]\n",
    "            if abs(sum(self.board[:, i])) == 3:\n",
    "                return self.board[0, i]\n",
    "        \n",
    "        if abs(sum(np.diag(self.board))) == 3:\n",
    "            return self.board[0, 0]\n",
    "        if abs(sum(np.diag(np.fliplr(self.board)))) == 3:\n",
    "            return self.board[0, 2]\n",
    "        \n",
    "        if len(self.get_valid_moves()) == 0:\n",
    "            return 0  # Draw\n",
    "        \n",
    "        return None  # Game not finished\n",
    "    \n",
    "    def step(self, action):\n",
    "        if not self.is_valid_move(action):\n",
    "            return self.get_state(), -10, True  # Invalid move penalty\n",
    "        \n",
    "        row, col = action // 3, action % 3\n",
    "        self.board[row][col] = self.current_player\n",
    "        \n",
    "        winner = self.check_winner()\n",
    "        done = winner is not None\n",
    "        \n",
    "        reward = 0\n",
    "        if done:\n",
    "            if winner == 0:\n",
    "                reward = 1  # Draw\n",
    "            elif winner == self.current_player:\n",
    "                reward = 5  # Win\n",
    "            else:\n",
    "                reward = -5  # Loss\n",
    "                \n",
    "        self.current_player *= -1\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, epsilon=0.1, alpha=0.1, gamma=0.9):\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.alpha = alpha      # Learning rate\n",
    "        self.gamma = gamma      # Discount factor\n",
    "    \n",
    "    def get_action(self, state, valid_moves):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(valid_moves)\n",
    "        \n",
    "        return self.get_best_action(state, valid_moves)\n",
    "    \n",
    "    def get_best_action(self, state, valid_moves):\n",
    "        best_value = float('-inf')\n",
    "        best_actions = []\n",
    "        \n",
    "        for action in valid_moves:\n",
    "            value = self.q_table[state][action]\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_actions = [action]\n",
    "            elif value == best_value:\n",
    "                best_actions.append(action)\n",
    "                \n",
    "        return random.choice(best_actions)\n",
    "    \n",
    "    def learn(self, state, action, reward, next_state, next_valid_moves):\n",
    "        if next_valid_moves:\n",
    "            next_value = max(self.q_table[next_state][next_action] \n",
    "                           for next_action in next_valid_moves)\n",
    "        else:\n",
    "            next_value = 0\n",
    "            \n",
    "        current_value = self.q_table[state][action]\n",
    "        self.q_table[state][action] = current_value + self.alpha * (\n",
    "            reward + self.gamma * next_value - current_value)\n",
    "\n",
    "def train_agent(episodes=10000):\n",
    "    env = TicTacToeEnv()\n",
    "    agent = QLearningAgent()\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            valid_moves = env.get_valid_moves()\n",
    "            action = agent.get_action(state, valid_moves)\n",
    "            \n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_valid_moves = env.get_valid_moves()\n",
    "            \n",
    "            agent.learn(state, action, reward, next_state, next_valid_moves)\n",
    "            state = next_state\n",
    "            \n",
    "        if episode % 1000 == 0:\n",
    "            print(f\"Episode {episode} completed\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def play_game(agent, human_first=True):\n",
    "    env = TicTacToeEnv()\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    def print_board():\n",
    "        symbols = {1: 'X', -1: 'O', 0: ' '}\n",
    "        for i in range(3):\n",
    "            print('-------------')\n",
    "            row = '|'\n",
    "            for j in range(3):\n",
    "                row += f' {symbols[env.board[i][j]]} |'\n",
    "            print(row)\n",
    "        print('-------------')\n",
    "    \n",
    "    def get_human_move():\n",
    "        while True:\n",
    "            try:\n",
    "                move = int(input(\"Enter your move (0-8): \"))\n",
    "                if 0 <= move <= 8 and env.is_valid_move(move):\n",
    "                    return move\n",
    "                print(\"Invalid move, try again\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a number between 0 and 8\")\n",
    "    \n",
    "    while not done:\n",
    "        print_board()\n",
    "        valid_moves = env.get_valid_moves()\n",
    "        \n",
    "        if (human_first and env.current_player == 1) or \\\n",
    "           (not human_first and env.current_player == -1):\n",
    "            action = get_human_move()\n",
    "        else:\n",
    "            action = agent.get_best_action(state, valid_moves)\n",
    "            print(f\"AI plays move: {action}\")\n",
    "        \n",
    "        state, reward, done = env.step(action)\n",
    "    \n",
    "    print_board()\n",
    "    winner = env.check_winner()\n",
    "    if winner == 0:\n",
    "        print(\"Game ended in a draw!\")\n",
    "    elif (winner == 1 and human_first) or (winner == -1 and not human_first):\n",
    "        print(\"You won!\")\n",
    "    else:\n",
    "        print(\"AI won!\")\n",
    "\n",
    "# Training and playing\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Training AI...\")\n",
    "    trained_agent = train_agent(episodes=10000)\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    while True:\n",
    "        human_first = input(\"Do you want to play first? (y/n): \").lower() == 'y'\n",
    "        play_game(trained_agent, human_first)\n",
    "        \n",
    "        if input(\"Play again? (y/n): \").lower() != 'y':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6659611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
